# hdu-edgecompute
/***层级越高，优先级越高，以下内容如果有层级越低优先级越高，纯属我记错了，因为越靠近边缘，节点所处层级越高（核心服务器的层级为0）***/
/***NP-Hard证明***/
基于全局透明的最优缓存策略
所有内容请求的平均访问跳数最小，核心服务器也是节点，并且Zxc一定是1（因为核心服务器拥有全部缓存）
Z是一个二维矩阵，Zij 表示内容i在节点j处是否缓存。Zij=0或1。
Dij表示i到j的最短路径长度。
U是一个二维矩阵，Uij表示从节点i发出的内容j的数量。
从节点i，发出的内容j的总路径长度为 Min(Uij * （D ic * （1-Zjk）+Dik* Zjk) 记P
P是一个二维矩阵，Pij表示从节点i出发的内容j的总访问跳数
那此时的就是求一个Z，使得P*（1，1，1，1，1，1，1）T 最小。
如果直接用穷举或者回溯，不可行。800内容，1000节点时，Z解的规模将会达到2^810000个， 完全不切实际。所以这是个NP-hard问题。
综上所述，在全局透明的情况下，求的最优缓存策略的时间复杂度远远高于O(2^(c*s))（c是内容种类数量，s是网络节点数量）,所以该问题是一个NP—Hard问题。
所以同质化缓存只存在理论上的最优解。
同理证明异质化缓存：
异质化缓存每个内容仅能存储在1个节点上，所以每个内容都有s个选择，且相互独立，所以解空间规模为O(s^c)。虽然规模相较于同质化缓存较小，但是依然是NP-Hard问题，
所以异质化缓存也只存在理论上的最优解。
已知：U，D
求：Z
/***NP-Hard证明结束   无论是同质化缓存还是异质化缓存，都仅存在理论上最优解***/

解决思路：
/**子域top k+p 内容的最优缓存策略**/
之所以不可解是因为解空间过于庞大。那么需要想办法缩小解空间。采用回溯剪枝的方式（可根据节点缓存空间大小等限制条件进行剪枝），但是无法从根本上缩小解空间。
既然不能直接从解空间入手，那么就考虑缩小问题域。
在新的分层模型中，以子域作为目标空间，将该空间中内容流行度排名top k个内容采用最优解法进行联合缓存（因为当前考虑
的是所有内容大小一致），同时保证k*s (s为当前子域的节点数量) 小于一个阈值（该阈值取决于该子域核节点的性能，为了试验方便在此设置为12）。这样能保证该子域中内容最流行的内容
在该子域是最优解。最流行的内容允许同质化缓存。    
同样的思路，在子域内，可以将内容流行度（排除top k的情况下）排名 top p个内容采用最优解（不允许同质化缓存）进行联合缓存，通知保证s^p 小于一个阈值（该阈值取决于
子域核节点的性能，为了实验方便，设置为4096）。如此一来，能保证子域内top k+p 个内容是最优解。      
为了实现上诉功能，需要保证：
1、核节点需要知道本子域所有节点，也需要记录所有流经本子域的请求（包括请求的内容以及请求的发出方）
注意：由核节点计算的最优解不是真正的缓存方式，只是一个缓存位置简报。核节点定期计算，将得出的缓存策略分发给子域内的所有节点，然后子域内节点在**下次**收到内容响应时，
根据该缓存策略来判断是否缓存（缓存策略可以为一个Map，也可以为一个二维矩阵，怎么方便实现怎么来）
在收到解矩阵后，每个节点都会将自己的缓存空间分为2部分，一部分是预留部分，即为top k+p个内容预备的。一部分是自用部分，该部分由其他策略进行分配。

/**子域内剩余缓存空间的有效利用**/
由于核节点计算能力已经被透支了，所以子域内剩余缓存空间最好是能够由各个子节点自主决定，在此我推荐H2RR策略


/**联合缓存时，空间争用问题**/
问题提出：节点A即是某个节点的下游子域节点，同时又是某几个节点的核节点。那么节点A的缓存空间实际上将会被2层争用。
问题解决：因为最终目的是降低缓存缓存跳数，所以越靠近边缘的决策优先级越高。在回溯过程中，下级决策优先于上级决策，且下级决策结果作为上级决策的限制条件（主要是剩余可缓存空间）
这就要求每个节点产出缓存解时，需要记录解来源。（每个节点维护一个数据结构，该数据结构记录本节点应该缓存的内容对象以及解来源（可用节点层级用作解来源，层级越低，优先级越高，若有不同来源的相同解，做链式层级））

问题提出：当缓存解到达节点时，发现当前节点的剩余缓存空间不足（解新增的缓存内容数量大于当前节点剩余缓存数量）
问题解决：对当前节点所有缓存内容进行解层级排序，淘汰掉层级最低的部分，留下层级最高的部分

问题提出：当同层级的解决方案进行争夺时怎么办? 例如一共只有10个坑位，0层级占了9个，1层级有4个，那么如何从1层级的4个中选择1个
问题解决：同层级发送过来的解决方案若出现互相竞争的情况，一定是因为上下两层同时决策导致的或者是由于上层解决方案版本过于陈旧导致的。证明：如果都是最新
且串行生成的解决方案，在0层方案生成后，1层方案生成时就会考虑到0层方案的占坑的限制。所以要么是同时生成，要么是1在0层之前生成。
先按照内容访问热度排序，再按照解决方案层级排序，这样同层级竞争就可以按照内容热度排序

/**内容历史流行度很高，但是当前已经不流行的内容**/
问题提出：某个内容在历史某时刻异常流行，导致该内容在某域内历史访问量及其庞大，但实际上该内容已经不流行，不适合用作缓存。
问题解决：每次访问都会进行时间留痕。可以划定时间区间（比如5分钟），在每次计算缓存解时，仅取最近一个时间区间内的。固定的时间区间可能导致过滤效应，所以
可以采用随机冷冻机制降低过滤效应的影响。随机因素，距离现在越久的记录，被加入统计的概率越小。距离现在越近的记录，被加入统计概率越大（无限趋近于1）
随机冷冻模型（即参与统计概率计算公式） 时间区间大小/（时间差+时间区间大小）   时间差越小越接近1，时间差越大越接近0。

/**缓存固化问题**/
问题提出：在实验过程中发现，每个节点的缓存替换率都很低。深究发现，在统计访问记录时，会将子域内部转发也统计进去，从而导致大量增加缓存节点的访问量就导致了缓存固化问题。
问题解决：给子域内部转发的请求打上标签，不记录。访问记录只记录来源于用户请求。

字典：
1、核心节点：特指云服务器
2、核节点：有下游子节点的服务器节点
3、边缘节点：没有下游服务器节点，与用户终端直连的节点（本实验中，边缘节点充当用户终端）