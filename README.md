# hdu-edgecompute
/***NP-Hard证明***/
基于全局透明的最优缓存策略
所有内容请求的平均访问跳数最小，核心服务器也是节点，并且Zxc一定是1（因为核心服务器拥有全部缓存）
Z是一个二维矩阵，Zij 表示内容i在节点j处是否缓存。Zij=0或1。
Dij表示i到j的最短路径长度。
U是一个二维矩阵，Uij表示从节点i发出的内容j的数量。
从节点i，发出的内容j的总路径长度为 Min(Uij * （D ic * （1-Zjk）+Dik* Zjk) 记P
P是一个二维矩阵，Pij表示从节点i出发的内容j的总访问跳数
那此时的就是求一个Z，使得P*（1，1，1，1，1，1，1）T 最小。
如果直接用穷举或者回溯，不可行。800内容，1000节点时，Z解的规模将会达到2^810000个， 完全不切实际。所以这是个NP-hard问题。
综上所述，在全局透明的情况下，求的最优缓存策略的时间复杂度远远高于O(2^(c*s))（c是内容种类数量，s是网络节点数量）,所以该问题是一个NP—Hard问题。
所以同质化缓存只存在理论上的最优解。
同理证明异质化缓存：
异质化缓存每个内容仅能存储在1个节点上，所以每个内容都有s个选择，且相互独立，所以解空间规模为O(s^c)。虽然规模相较于同质化缓存较小，但是依然是NP-Hard问题，
所以异质化缓存也只存在理论上的最优解。
已知：U，D
求：Z
/***NP-Hard证明结束   无论是同质化缓存还是异质化缓存，都仅存在理论上最优解***/

解决思路：
/**子域top k+p 内容的最优缓存策略**/
之所以不可解是因为解空间过于庞大。那么需要想办法缩小解空间。采用回溯剪枝的方式（可根据节点缓存空间大小等限制条件进行剪枝），但是无法从根本上缩小解空间。
既然不能直接从解空间入手，那么就考虑缩小问题域。
在新的分层模型中，以子域作为目标空间，将该空间中内容流行度排名top k个内容采用最优解法进行联合缓存（因为当前考虑
的是所有内容大小一致），同时保证k*s (s为当前子域的节点数量) 小于一个阈值（该阈值取决于该子域核节点的性能，为了试验方便在此设置为12）。这样能保证该子域中内容最流行的内容
在该子域是最优解。最流行的内容允许同质化缓存。    
同样的思路，在子域内，可以将内容流行度（排除top k的情况下）排名 top p个内容采用最优解（不允许同质化缓存）进行联合缓存，通知保证s^p 小于一个阈值（该阈值取决于
子域核节点的性能，为了实验方便，设置为4096）。如此一来，能保证子域内top k+p 个内容是最优解。      
为了实现上诉功能，需要保证：
1、核节点需要知道本子域所有节点，也需要记录所有流经本子域的请求（包括请求的内容以及请求的发出方）
注意：由核节点计算的最优解不是真正的缓存方式，只是一个缓存位置简报。核节点定期计算，将得出的缓存策略分发给子域内的所有节点，然后子域内节点在**下次**收到内容响应时，
根据该缓存策略来判断是否缓存（缓存策略可以为一个Map，也可以为一个二维矩阵，怎么方便实现怎么来）
在收到解矩阵后，每个节点都会将自己的缓存空间分为2部分，一部分是预留部分，即为top k+p个内容预备的。一部分是自用部分，该部分由其他策略进行分配。

/**子域内剩余缓存空间的有效利用**/
由于核节点计算能力已经被透支了，所以子域内剩余缓存空间最好是能够由各个子节点自主决定，在此我推荐H2RR策略

